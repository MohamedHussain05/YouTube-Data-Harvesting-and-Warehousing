{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "import pandas as pd\n",
    "import re\n",
    "import streamlit as st\n",
    "import mysql.connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Api_connect():\n",
    "    Api_id=\"AIzaSyA3W0o7_mql2GQcR0ZfRCJgUm50vF9_L9Y\"\n",
    "    \n",
    "    api_service_name=\"youtube\"\n",
    "    api_version=\"v3\"\n",
    "    \n",
    "    youtube=build(api_service_name,api_version,developerKey=Api_id)\n",
    "    return youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube=Api_connect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "request=youtube.channels().list(\n",
    "        part=\"snippet,contentDetails,Statistics\",\n",
    "        id=\"UCnjU1FHmao9YNfPzE039YTw\"\n",
    "    )\n",
    "response=request.execute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=response\n",
    "print(b)\n",
    "c=list(response)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=list(response['items'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(a)\n",
    "print(len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channel_info(channel_id):\n",
    "    request=youtube.channels().list(\n",
    "        part=\"snippet,contentDetails,Statistics\",\n",
    "        id=channel_id\n",
    "    )\n",
    "    response=request.execute()\n",
    "    \n",
    "    for i in range(0,len(response['items'])):\n",
    "        data=dict(Channel_name=response['items'][i]['snippet']['title'],\n",
    "                  Channel_id=response['items'][i]['id'],\n",
    "                  Subscription_Count=response['items'][i]['statistics']['subscriberCount'],\n",
    "                  Views=response['items'][i]['statistics']['viewCount'],\n",
    "                  Total_Videos=response['items'][i]['statistics']['videoCount'],\n",
    "                  Channel_Description=response['items'][i]['snippet']['description'],\n",
    "                  Playlist_Id=response['items'][i]['contentDetails']['relatedPlaylists']['uploads'])\n",
    "        return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " g=get_channel_info(\"UCXPTGN7Kw1M2kXUzQCyG-zg\")\n",
    " \n",
    " print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_videos_ids(channel_id):\n",
    "    video_ids=[]\n",
    "\n",
    "    reponse=youtube.channels().list(id=channel_id,\n",
    "                                    part='contentDetails').execute()\n",
    "    Playlist_Id=reponse['items'][0]['contentDetails']['relatedPlaylists']['uploads']\n",
    "\n",
    "    next_page_token=None\n",
    "    while True:\n",
    "        response1=youtube.playlistItems().list(\n",
    "                part='snippet',\n",
    "                playlistId=Playlist_Id,\n",
    "                maxResults=50,\n",
    "                pageToken=next_page_token).execute()\n",
    "        for i in range(len(response1['items'])):\n",
    "                video_ids.append(response1['items'][i]['snippet']['resourceId']['videoId'])\n",
    "        next_page_token=response1.get('nextPageToken')\n",
    "        if next_page_token==None:\n",
    "            break\n",
    "    return video_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Video_ids=get_videos_ids('UCXPTGN7Kw1M2kXUzQCyG-zg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Video_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Video_ids[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response['items']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_info(Video_ids):\n",
    "    video_data=[]\n",
    "\n",
    "    for video_id in Video_ids:\n",
    "        response=youtube.videos().list(\n",
    "            part=\"snippet,contentDetails,statistics\",\n",
    "            id=video_id\n",
    "        ).execute()\n",
    "        \n",
    "        for items in response['items']:\n",
    "            data=dict(\n",
    "                        Channel_Name = items['snippet']['channelTitle'],\n",
    "                        Channel_Id = items['snippet']['channelId'],\n",
    "                        Video_Id =items['id'],\n",
    "                        Title =items['snippet']['title'],\n",
    "                        Tags =items['snippet'].get('tags'),\n",
    "                        Thumbnail =items['snippet']['thumbnails']['default']['url'],\n",
    "                        Description = items['snippet'].get('description'),\n",
    "                        Published_Date =items['snippet']['publishedAt'],\n",
    "                        Duration =items['contentDetails']['duration'],\n",
    "                        Views =items['statistics'].get('viewCount'),\n",
    "                        Likes =items['statistics'].get('likeCount'),\n",
    "                        Comments = items['statistics'].get('commentCount'),\n",
    "                        Favorite_Count =items['statistics']['favoriteCount'],\n",
    "                        Definition =items['contentDetails']['definition'],\n",
    "                        Caption_Status = items['contentDetails']['caption'] )\n",
    "            video_data.append(data)\n",
    "    return video_data\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_details=get_video_info('UCXPTGN7Kw1M2kXUzQCyG-zg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_details[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comment_info(Video_ids):\n",
    "     Comment_Information = []\n",
    "     try:\n",
    "          for video_id in Video_ids:\n",
    "               response=youtube.commentThreads().list(\n",
    "                    part='snippet',\n",
    "                    videoId=video_id,\n",
    "                    maxResults=100).execute()\n",
    "                    \n",
    "               for items in response['items']:\n",
    "                    data=dict(Comment_Id =items['snippet']['topLevelComment']['id'],\n",
    "                              Video_Id =items['snippet']['videoId'],\n",
    "                              Comment_Text =items['snippet']['topLevelComment']['snippet']['textOriginal'],\n",
    "                              Comment_Author =items['snippet']['topLevelComment']['snippet']['authorDisplayName'],\n",
    "                              Comment_Published=items['snippet']['topLevelComment']['snippet']['publishedAt'])\n",
    "                    Comment_Information.append(data)\n",
    "     except:\n",
    "          pass\n",
    "     return Comment_Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=get_comment_info(Video_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_playlist_info(channel_id):\n",
    "    All_data = []\n",
    "    next_page_token = None\n",
    "    next_page = True\n",
    "    while next_page:\n",
    "\n",
    "        request = youtube.playlists().list(\n",
    "            part=\"snippet,contentDetails\",\n",
    "            channelId=channel_id,\n",
    "            maxResults=50,\n",
    "            pageToken=next_page_token\n",
    "            )\n",
    "        response = request.execute()\n",
    "\n",
    "        for item in response['items']: \n",
    "            data={'PlaylistId':item['id'],\n",
    "                    'Title':item['snippet']['title'],\n",
    "                    'ChannelId':item['snippet']['channelId'],\n",
    "                    'ChannelName':item['snippet']['channelTitle'],\n",
    "                    'PublishedAt':item['snippet']['publishedAt'],\n",
    "                    'VideoCount':item['contentDetails']['itemCount']}\n",
    "            All_data.append(data)\n",
    "        next_page_token = response.get('nextPageToken')\n",
    "        if next_page_token is None:\n",
    "            next_page=False\n",
    "    return All_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting MongoDB and creating collections\n",
    "import pymongo\n",
    "client=pymongo.MongoClient(\"mongodb+srv://hussain:1234@cluster0.0wossp3.mongodb.net/?retryWrites=true&w=majority\")\n",
    "db=client[\"Youtube_data\"]\n",
    "coll1=db[\"channel_details\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel_details(channel_id):\n",
    "    ch_details=get_channel_info(channel_id)\n",
    "    pl_details=get_playlist_info(channel_id)\n",
    "    vi_ids=get_videos_ids(channel_id)\n",
    "    vi_details=get_video_info(vi_ids)\n",
    "    com_details=get_comment_info(vi_ids)\n",
    "    \n",
    "    coll1=db[\"channel_details\"]\n",
    "    coll1.insert_one({\"channel_information\":ch_details,\n",
    "                      \"playlist_information\":pl_details,\n",
    "                      \"video_information\":vi_details,\n",
    "                     \"comment_information\":com_details})\n",
    "    return \"upload success\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_details(\"UCNFa9HtV-xYSRuTazrJhIFA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def channels_table():\n",
    "    mydb=mysql.connector.connect(\n",
    "        host='localhost',\n",
    "        user='root',\n",
    "        passwd=\"1234\",\n",
    "        auth_plugin='mysql_native_password')\n",
    "    mycursor=mydb.cursor(buffered=True)\n",
    "    \n",
    "    #Table creation for channels in MySql\n",
    "    mycursor.execute('create database if not exists youtube_data')\n",
    "    mycursor.execute(\"use  youtube_data\")\n",
    "    mycursor.execute(\"drop table if exists channels\")\n",
    "    mydb.commit()\n",
    "    try:\n",
    "        mycursor.execute('''create table if not exists channels(Channel_Name varchar(100),\n",
    "                                                                Channel_Id varchar(50) primary key,\n",
    "                                                                Subscribers bigint,\n",
    "                                                                Views bigint,\n",
    "                                                                Total_Videos bigint,\n",
    "                                                                Channel_Description text,\n",
    "                                                                Playlist_Id varchar(80))''')\n",
    "        mydb.commit()\n",
    "    except:\n",
    "        print(\"Table already exists\")\n",
    "        \n",
    "    #Extracting  channels details from mongodb and making it to DataFrame \n",
    "    ch_list=[]\n",
    "    coll1=db[\"channel_details\"]\n",
    "    for ch in coll1.find({},{\"_id\":0,\"channel_information\":1}):\n",
    "        ch_list.append(ch['channel_information'])\n",
    "    df=pd.DataFrame(ch_list)\n",
    "\n",
    "    #Pushing data to Mysql\n",
    "    for index,row in df.iterrows():\n",
    "        insert_query='''insert into channels(Channel_Name,\n",
    "                                            Channel_Id,\n",
    "                                            Subscribers,\n",
    "                                            Views,\n",
    "                                            Total_Videos,\n",
    "                                            Channel_Description,\n",
    "                                            Playlist_Id)\n",
    "                                            \n",
    "                                            values(%s,%s,%s,%s,%s,%s,%s)'''\n",
    "        values=(row['Channel_name'],\n",
    "                row['Channel_id'],\n",
    "                row['Subscription_Count'],\n",
    "                row['Views'],\n",
    "                row['Total_Videos'],\n",
    "                row['Channel_Description'],\n",
    "                row['Playlist_Id'])\n",
    "        try:\n",
    "            mycursor.execute(insert_query,values)\n",
    "            mydb.commit()\n",
    "        except mysql.connector.errors.IntegrityError:\n",
    "            print(\"Channel values already inserted\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def playlist_table():\n",
    "    mydb=mysql.connector.connect(\n",
    "            host='localhost',\n",
    "            user='root',\n",
    "            passwd=\"1234\",\n",
    "            auth_plugin='mysql_native_password')\n",
    "    mycursor=mydb.cursor(buffered=True)\n",
    "        \n",
    "    #Table creation for channels in MySql\n",
    "    mycursor.execute(\"create database if not exists youtube_data\")\n",
    "    mycursor.execute(\"use youtube_data\")\n",
    "    mycursor.execute(\"drop table if exists playlists\")\n",
    "    mydb.commit()\n",
    "    try:\n",
    "        mycursor.execute('''create table if not exists playlists(Playlist_Id varchar(100) primary key,\n",
    "                                                                    Title varchar(100),\n",
    "                                                                    Channel_Id varchar(100),\n",
    "                                                                    Channel_Name varchar(100),\n",
    "                                                                    Published_At timestamp,\n",
    "                                                                    Video_Count int)''')\n",
    "        mydb.commit()\n",
    "\n",
    "    except:\n",
    "        print(\"Error in creating table\")\n",
    "        \n",
    "    #Extracting  playlists details from mongodb and making it to DataFrame\n",
    "    pl_list=[]\n",
    "    db=client[\"Youtube_data\"]\n",
    "    coll1=db['channel_details']\n",
    "    for pl_data in coll1.find({},{'_id':0,'playlist_information':1}):\n",
    "        for i in range(len(pl_data['playlist_information'])):\n",
    "            pl_list.append(pl_data['playlist_information'][i])\n",
    "    df1=pd.DataFrame(pl_list)\n",
    "\n",
    "    #Pushing data to Mysql\n",
    "    for index,row in df1.iterrows():\n",
    "        \n",
    "        row['PublishedAt'] = pd.to_datetime(row['PublishedAt']).strftime('%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "        insert_query='''insert into playlists(Playlist_Id,\n",
    "                                            Title,\n",
    "                                            Channel_Id,\n",
    "                                            Channel_Name,\n",
    "                                            Published_At,\n",
    "                                            Video_Count)\n",
    "                                                                        \n",
    "                                            values(%s,%s,%s,%s,%s,%s)'''\n",
    "    \n",
    "\n",
    "        values=(row['PlaylistId'],\n",
    "                                row['Title'],\n",
    "                                row['ChannelId'],\n",
    "                                row['ChannelName'],\n",
    "                                row['PublishedAt'],\n",
    "                                row['VideoCount'])\n",
    "        try:\n",
    "            mycursor.execute(insert_query,values)\n",
    "            mydb.commit()\n",
    "        except mysql.connector.errors.IntegrityError:\n",
    "                print(\"Channel values already inserted\")\n",
    "        \n",
    "                    \n",
    "                                                                    \n",
    "                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def videos_table():\n",
    "    mydb=mysql.connector.connect(\n",
    "                host='localhost',\n",
    "                user='root',\n",
    "                passwd=\"1234\",\n",
    "                auth_plugin='mysql_native_password')\n",
    "    mycursor=mydb.cursor(buffered=True)\n",
    "\n",
    "    #Table creation for videos in MySql\n",
    "    mycursor.execute(\"create database if not exists youtube_data\")\n",
    "    mycursor.execute(\"use youtube_data\")\n",
    "    mycursor.execute(\"drop table if exists videos\")\n",
    "\n",
    "    try:\n",
    "        mycursor.execute('''create table if not exists videos(Channel_Name varchar(100),\n",
    "                                                            Channel_Id varchar(50),\n",
    "                                                            Video_Id varchar(50) primary key,\n",
    "                                                            Title varchar(200),\n",
    "                                                            Tags text,\n",
    "                                                            Thumbnail varchar(200),\n",
    "                                                            Description text,\n",
    "                                                            Published_Date timestamp,\n",
    "                                                            Duration int,\n",
    "                                                            Views bigint,\n",
    "                                                            Likes bigint,\n",
    "                                                            Comments int,\n",
    "                                                            Favorite_Count int,\n",
    "                                                            Definition varchar(10),\n",
    "                                                            Caption_Status varchar(50))''')\n",
    "        mydb.commit()\n",
    "    except:\n",
    "        print(\"Error in creating videos table\")  \n",
    "        \n",
    "    #Extracting  videos details from mongodb and making it to DataFrame \n",
    "\n",
    "    vi_list=[]\n",
    "    for vi_data in coll1.find({},{'_id':0,'video_information':1}):\n",
    "        for i in range(len(vi_data['video_information'])):\n",
    "            vi_list.append(vi_data['video_information'][i])\n",
    "    df2=pd.DataFrame(vi_list)\n",
    "\n",
    "    # Pushing data to MySQL\n",
    "    for index, row in df2.iterrows():\n",
    "        # Format Published Date\n",
    "        row['Published_Date'] = pd.to_datetime(row['Published_Date']).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "        # Extract minutes and seconds from Duration (handling potential missing 'M')\n",
    "        duration_str = row['Duration']\n",
    "        match = re.search(r\"PT(?P<minutes>\\d+)M(?P<seconds>\\d+)S\", duration_str)\n",
    "        if match:\n",
    "            minutes = int(match.group('minutes'))\n",
    "            seconds = int(match.group('seconds'))\n",
    "\n",
    "        # Convert to total duration in seconds\n",
    "        row['Duration'] = minutes * 60 + seconds\n",
    "        \n",
    "\n",
    "\n",
    "        # Define insert query outside the loop (one time)\n",
    "        insert_query = \"\"\"insert into videos(Channel_Name,\n",
    "                                            Channel_Id,\n",
    "                                            Video_Id,\n",
    "                                            Title,\n",
    "                                            Tags,\n",
    "                                            Thumbnail,\n",
    "                                            Description,\n",
    "                                            Published_Date,\n",
    "                                            Duration,\n",
    "                                            Views,\n",
    "                                            Likes,\n",
    "                                            Comments,\n",
    "                                            Favorite_Count,\n",
    "                                            Definition,\n",
    "                                            Caption_Status)\n",
    "                        values(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)\"\"\"\n",
    "\n",
    "        # Create values tuple from DataFrame row\n",
    "        values = tuple(row[col] for col in df2.columns)\n",
    "\n",
    "        # Handle Tags if it's a list\n",
    "        if isinstance(row['Tags'], list):\n",
    "            values = values[:4] + (','.join(row['Tags']),) + values[5:]\n",
    "\n",
    "        try:\n",
    "            mycursor.execute(insert_query, values)\n",
    "            mydb.commit()\n",
    "        except mysql.connector.errors.IntegrityError:\n",
    "            print(\"Channel values already inserted\")\n",
    "        except mysql.connector.Error as err:\n",
    "            print(\"Error inserting data:\", err)\n",
    "\n",
    "    # Close the connection\n",
    "    mydb.close()\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comments_table():\n",
    "    mydb=mysql.connector.connect(\n",
    "                    host='localhost',\n",
    "                    user='root',\n",
    "                    passwd=\"1234\",\n",
    "                    auth_plugin='mysql_native_password')\n",
    "    mycursor=mydb.cursor(buffered=True)\n",
    "\n",
    "    #Table creation for videos in MySql\n",
    "    mycursor.execute(\"create database if not exists youtube_data\")\n",
    "    mycursor.execute(\"use youtube_data\")\n",
    "    mycursor.execute(\"drop table if exists comments\")\n",
    "\n",
    "    mycursor.execute('''create table if not exists comments(Comment_Id varchar(100) primary key,\n",
    "                                                            Video_Id varchar(50),\n",
    "                                                            Comment_Text text,\n",
    "                                                            Comment_Author varchar(150),\n",
    "                                                            Comment_Published timestamp)''')\n",
    "    mydb.commit()\n",
    "\n",
    "    #Retriving data from MongoDB\n",
    "    com_list=[]\n",
    "    for com_data in coll1.find({},{'_id':0,'comment_information':1}):\n",
    "        for i in range(len(com_data['comment_information'])):   \n",
    "            com_list.append(com_data['comment_information'][i])\n",
    "    df3=pd.DataFrame(com_list)\n",
    "\n",
    "    #inserting comments data into Mysql\n",
    "    for index,row in df3.iterrows():\n",
    "            row['Comment_Published']=pd.to_datetime(row['Comment_Published']).strftime('%Y-%m-%d %H:%M:%S')\n",
    "            insert_query='''insert into comments(Comment_Id,\n",
    "                                                    Video_Id,\n",
    "                                                    Comment_Text,\n",
    "                                                    Comment_Author,\n",
    "                                                    Comment_Published\n",
    "                                                    )\n",
    "                                                    \n",
    "                                                    values(%s,%s,%s,%s,%s)'''\n",
    "                                                    \n",
    "            values=(row['Comment_Id'],\n",
    "                    row['Video_Id'],\n",
    "                    row['Comment_Text'],\n",
    "                    row['Comment_Author'],\n",
    "                    row['Comment_Published'])\n",
    "            \n",
    "            try:\n",
    "                    mycursor.execute(insert_query,values)\n",
    "                    mydb.commit()\n",
    "            except mysql.connector.errors.IntegrityError:\n",
    "                    print(\"Comments values already inserted\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tables():\n",
    "    comments_table()\n",
    "    videos_table()\n",
    "    playlist_table()\n",
    "    channels_table()\n",
    "    \n",
    "    return 'Tables Created Succuesfully'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables=tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_channels_table():\n",
    "    ch_list=[]\n",
    "    coll1=db[\"channel_details\"]\n",
    "    for ch in coll1.find({},{\"_id\":0,\"channel_information\":1}):\n",
    "        ch_list.append(ch['channel_information'])\n",
    "    df=st.dataframe(ch_list)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_playlists_table():\n",
    "    pl_list=[]\n",
    "    db=client[\"Youtube_data\"]\n",
    "    coll1=db['channel_details']\n",
    "    for pl_data in coll1.find({},{'_id':0,'playlist_information':1}):\n",
    "        for i in range(len(pl_data['playlist_information'])):\n",
    "            pl_list.append(pl_data['playlist_information'][i])\n",
    "    df1=st.dataframe(pl_list)\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_videos_table():   \n",
    "    vi_list=[]\n",
    "    for vi_data in coll1.find({},{'_id':0,'video_information':1}):\n",
    "        for i in range(len(vi_data['video_information'])):\n",
    "            vi_list.append(vi_data['video_information'][i])\n",
    "    df2=st.dataframe(vi_list)\n",
    "    \n",
    "    return df2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_comments_table():\n",
    "    com_list=[]\n",
    "    for com_data in coll1.find({},{'_id':0,'comment_information':1}):\n",
    "        for i in range(len(com_data['comment_information'])):   \n",
    "            com_list.append(com_data['comment_information'][i])\n",
    "    df3=st.dataframe(com_list)\n",
    "    \n",
    "    return df3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Streamlit \n",
    "with st.sidebar:\n",
    "    st.title(\":red[YOUTUBE DATA HARVESTING AND WAREHOUSING]\")\n",
    "    st.header(\"Skill Take Away\")\n",
    "    st.caption(\"MongoDB\")\n",
    "    st.caption(\"Pyton Scripting\")\n",
    "    st.caption(\"Api Integration\")\n",
    "    st.caption(\"Data Collection\")\n",
    "    st.caption(\"Data Management Using MongoDB and SQL\")\n",
    "\n",
    "channel_id=st.text_input(\"Enter the channel ID\")\n",
    "\n",
    "if st.button(\"collect and store data\"):\n",
    "    ch_ids=[]\n",
    "    db=client[\"Youtube_data\"]\n",
    "    coll1=db[\"channel_details\"]\n",
    "    for ch_data in coll1.find({},{\"_id\":0,\"channel_information\":1}):\n",
    "        ch_ids.append(ch_data[\"channel_information\"][\"Channel_Id\"])\n",
    "        \n",
    "    if channel_id in ch_ids:\n",
    "        st.success(\"Channels details of given channle is already exists\")\n",
    "    \n",
    "    else:\n",
    "        insert=channel_details(channel_id)\n",
    "        st.success(insert)\n",
    "        \n",
    "if st.button(\"Migrate to SQL\"):\n",
    "    Tables=tables()\n",
    "    st.success(Tables)\n",
    "    \n",
    "show_tables=st.radio(\"SELECT THE TABLE FOR VIEW\",(\"CHANNELS\",\"PLAYLISTS\",\"VIDEOS\",\"COMMENTS\"))\n",
    "\n",
    "if show_tables=='CHANNELS':\n",
    "    show_channels_table()\n",
    "    \n",
    "elif show_tables=='PLAYLISTS':\n",
    "    show_playlists_table()\n",
    "    \n",
    "elif show_tables=='VIDEOS':\n",
    "    show_videos_table()\n",
    "\n",
    "elif show_tables=='COMMENTS':\n",
    "    show_comments_table()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb=mysql.connector.connect(\n",
    "                host='localhost',\n",
    "                user='root',\n",
    "                passwd=\"1234\",\n",
    "                auth_plugin='mysql_native_password')\n",
    "mycursor=mydb.cursor(buffered=True)\n",
    "mycursor.execute('use youtube_data')\n",
    "\n",
    "questions=st.selectbox(\"Select Your Quesion\",(\"1. All the videos and the channel name\",\n",
    "                                              \"2. channels with most number of videos\",\n",
    "                                              \"3. 10 most viewed videos\",\n",
    "                                              \"4. comments in each videos\",\n",
    "                                              \"5. Videos with higest likes\",\n",
    "                                              \"6. likes of all videos\",\n",
    "                                              \"7. views of each channel\",\n",
    "                                              \"8. videos published in the year of 2022\",\n",
    "                                              \"9. average duration of all videos in each channel\",\n",
    "                                              \"10. videos with highest number of comments\"))\n",
    "if questions==\"1. All the videos and the channel name\":\n",
    "    query1=('''select title as video, channel_name from videos''')\n",
    "    mycursor.execute(query1)\n",
    "    mydb.commit()\n",
    "    t1=mycursor.fetchall()\n",
    "    df=pd.DataFrame(t1,columns=['Video_Title','Channel_name'])\n",
    "    st.write(df)\n",
    "    \n",
    "elif questions==\"2. channels with most number of videos\":\n",
    "    query2=('''select Channel_Name,Total_Videos as Videos_count from channels\n",
    "                order by Total_Videos desc''')\n",
    "    mycursor.execute(query2)\n",
    "    mydb.commit()\n",
    "    t2=mycursor.fetchall()\n",
    "    df2=pd.DataFrame(t2,columns=['Channel_Name','Videos_count'])\n",
    "    st.write(df2)\n",
    "    \n",
    "elif questions==\"3. 10 most viewed videos\":\n",
    "    query3=('''select Views,Channel_Name,Title as Video_Title\n",
    "                from videos\n",
    "                where Views is not null\n",
    "                order by Views desc\n",
    "                limit 10''')\n",
    "    mycursor.execute(query3)\n",
    "    mydb.commit()\n",
    "    t3=mycursor.fetchall()\n",
    "    df3=pd.DataFrame(t3,columns=['Views','Channel_Name','Video_Title'])\n",
    "    st.write(df3)\n",
    "    \n",
    "elif questions==\"4. comments in each videos\":\n",
    "    query4=('''select Comments as Comments_Count,Title as Video_Title\n",
    "                FROM videos\n",
    "                where Comments is not null\n",
    "                order by Comments desc''')\n",
    "    mycursor.execute(query4)\n",
    "    mydb.commit()\n",
    "    t4=mycursor.fetchall()\n",
    "    df4=pd.DataFrame(t4,columns=['Comments_Count','Video_Title'])\n",
    "    st.write(df4)\n",
    "    \n",
    "elif questions==\"5. Videos with higest likes\":\n",
    "    query5=('''select Likes as Likes_Count, Title as Video_Title,Channel_Name\n",
    "                FROM videos\n",
    "                where likes is not null\n",
    "                order by Likes desc''')\n",
    "    mycursor.execute(query5)\n",
    "    mydb.commit()\n",
    "    t5=mycursor.fetchall()\n",
    "    df5=pd.DataFrame(t5,columns=['Likes_Count','Video_Title','Channel_Name'])\n",
    "    st.write(df5)\n",
    "    \n",
    "elif questions==\"6. likes of all videos\":\n",
    "    query6=('''use youtube_data;\n",
    "                select likes as Like_count,title as video_title\n",
    "                from videos \n",
    "                order by Likes desc''')\n",
    "    mycursor.execute(query6)\n",
    "    mydb.commit()\n",
    "    t6=mycursor.fetchall()\n",
    "    df6=pd.DataFrame(t6,columns=['Likes_Count','Video_Title'])\n",
    "    st.write(df6)\n",
    "    \n",
    "elif questions==\"7. views of each channel\":\n",
    "    query7=('''select Channel_Name,Views as total_views from channels''')\n",
    "    mycursor.execute(query7)\n",
    "    mydb.commit()\n",
    "    t7=mycursor.fetchall()\n",
    "    df7=pd.DataFrame(t7,columns=['Channel_Name','total_view'])\n",
    "    st.write(df7)\n",
    "\n",
    "elif questions==\"8. videos published in the year of 2022\":\n",
    "    query8=('''select Title as Video_title,Published_Date as released_2022,Channel_Name from videos\n",
    "                where extract(year from Published_Date)=2022''')\n",
    "    mycursor.execute(query8)\n",
    "    mydb.commit()\n",
    "    t8=mycursor.fetchall()\n",
    "    df8=pd.DataFrame(t8,columns=['Video_title','released_2022','Channel_Name'])\n",
    "    st.write(df8)\n",
    "    \n",
    "elif questions==\"9. average duration of all videos in each channel\":\n",
    "    query9=('''use youtube_data;\n",
    "                select Channel_Name,avg(Duration) as Average_Duration  \n",
    "                from videos\n",
    "                group by Channel_Name''')\n",
    "    mycursor.execute(query9)\n",
    "    mydb.commit()\n",
    "    t9=mycursor.fetchall()\n",
    "    df9=pd.DataFrame(t9,columns=['Channel_Name','Average_Duration'])\n",
    "    st.write(df9)\n",
    "    \n",
    "elif questions==\"10. videos with highest number of comments\":\n",
    "    query10=('''select Title as Video_Title,Comments as Comments_count,Channel_Name\n",
    "                from videos\n",
    "                where Comments is not null\n",
    "                order by Comments desc''')\n",
    "    mycursor.execute(query10)\n",
    "    mydb.commit()\n",
    "    t10=mycursor.fetchall()\n",
    "    df10=pd.DataFrame(t10,columns=['Video_Title','Comments_count','Channel_Name'])\n",
    "    st.write(df10)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb=mysql.connector.connect(\n",
    "                host='localhost',\n",
    "                user='root',\n",
    "                passwd=\"1234\",\n",
    "                auth_plugin='mysql_native_password')\n",
    "mycursor=mydb.cursor(buffered=True)\n",
    "\n",
    "mycursor.execute('use youtube_data')\n",
    "elif questions==\"10. videos with highest number of comments\":\n",
    "    query10=('''select Title as Video_Title,Comments as Comments_count,Channel_Name\n",
    "                from videos\n",
    "                where Comments is not null\n",
    "                order by Comments desc''')\n",
    "    mycursor.execute(query10)\n",
    "    mydb.commit()\n",
    "    t10=mycursor.fetchall()\n",
    "    df10=pd.DataFrame(t10,columns=['Video_Title','Comments_count','Channel_Name'])\n",
    "    st.write(df10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video_Title</th>\n",
       "      <th>Channel_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#shortsvideo ‡Æö‡Æµ‡ØÅ‡Æ§‡Æø ‡Æ∞‡ÆÆ‡Æ≤‡Ææ‡Æ©‡Øç ‡ÆÆ‡Ææ‡Æ§‡Æ§‡Øç‡Æ§‡Æø‡Æ≤‡Øç ‡Æö‡Ææ‡Æ™‡Øç‡Æ™‡Ææ‡Æü‡Øç‡Æü‡ØÅ...</td>\n",
       "      <td>JUST GALATTA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Madan gowri phone call #shorts</td>\n",
       "      <td>Mind of Moto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GOOD NEWS FOR SAUDI HOUSE DRIVERüåπ ‡Æ®‡ÆÆ‡Øç‡ÆÆ ‡Æä‡Æ∞‡Øç‡Æ≤ ‡Æá‡Æ®...</td>\n",
       "      <td>JUST GALATTA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2 types of YouTube Content ||Khalfan fills</td>\n",
       "      <td>Khalfan Fills</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>üò± ‡Æï‡Ææ‡Æ§‡Æ≤‡Æ∞‡Øç‡Æï‡Æ≥‡Øç ‡Æí‡Æ©‡Øç‡Æ±‡ØÅ ‡Æï‡ØÇ‡Æü‡ØÅ‡ÆÆ‡Øç ‡Æá‡Æü‡ÆÆ‡Øçüò±couple hills in ...</td>\n",
       "      <td>JUST GALATTA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>‡Æí‡Æ∞‡Øá ‡Æü‡Øà‡ÆÆ‡Øç‡Æ≤ ‡Æá‡Æ§‡Øç‡Æ§‡Æ©‡Øà SHOW ‡Æ§‡Æ≥‡Æ™‡Æ§‡Æø ‡ÆÆ‡Ææ‡Æ∏‡Øç ‡Æ™‡Æ£‡Øç‡Æ£‡Æø‡Æü‡Øç‡Æü‡Ææ‡Æ∞‡ØÅ ‡Æö...</td>\n",
       "      <td>JUST GALATTA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>üî• ‡Æí‡Æ∞‡ØÅ ‡Æµ‡Æ¥‡Æø‡ÆØ‡Ææ ‡Æï‡Æ©‡Æµ‡ØÅ ‡Æ®‡Æø‡Æ©‡Øà‡Æµ‡Ææ‡Æ©‡Æ§‡ØÅüéâ #shortsvideo #just...</td>\n",
       "      <td>JUST GALATTA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>‡Æ™‡ØÅ‡Æ§‡ØÅ‡Æö‡Ææ ‡Æê ‡Æ™‡Øã‡Æ©‡Øç ‡Æµ‡Ææ‡Æô‡Øç‡Æï‡ØÅ‡Æ©‡Ææ ‡Æá‡Æ™‡Øç‡Æ™‡Æü‡Æø‡Æ§‡Øç‡Æ§‡Ææ‡Æ©‡Øç ‡Æ™‡Øã‡Æ≤ üî• ‡Æ§‡Æ∞‡ÆÆ‡Ææ...</td>\n",
       "      <td>JUST GALATTA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042</th>\n",
       "      <td>JUSTGALATTA FACK ID SCAMMER üôè ‡Æ§‡ÆØ‡Æµ‡ØÅ ‡Æö‡ØÜ‡Æû‡Øç‡Æö‡ØÅ ‡ÆØ‡Ææ‡Æ∞‡ØÅ...</td>\n",
       "      <td>JUST GALATTA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>ZAM ZAM BRIYANIüî• ‡Æ™‡Æø‡Æ∞‡Æø‡ÆØ‡Ææ‡Æ£‡Æø‡Æ≤ ‡Æá‡Æ™‡Øç‡Æ™‡Æü‡Æø ‡Æï‡ØÇ‡Æü ‡Æá‡Æ∞‡ØÅ‡Æï‡Øç‡Æï‡ØÅ‡ÆÆ...</td>\n",
       "      <td>JUST GALATTA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1044 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Video_Title   Channel_name\n",
       "0     #shortsvideo ‡Æö‡Æµ‡ØÅ‡Æ§‡Æø ‡Æ∞‡ÆÆ‡Æ≤‡Ææ‡Æ©‡Øç ‡ÆÆ‡Ææ‡Æ§‡Æ§‡Øç‡Æ§‡Æø‡Æ≤‡Øç ‡Æö‡Ææ‡Æ™‡Øç‡Æ™‡Ææ‡Æü‡Øç‡Æü‡ØÅ...   JUST GALATTA\n",
       "1                        Madan gowri phone call #shorts   Mind of Moto\n",
       "2     GOOD NEWS FOR SAUDI HOUSE DRIVERüåπ ‡Æ®‡ÆÆ‡Øç‡ÆÆ ‡Æä‡Æ∞‡Øç‡Æ≤ ‡Æá‡Æ®...   JUST GALATTA\n",
       "3            2 types of YouTube Content ||Khalfan fills  Khalfan Fills\n",
       "4     üò± ‡Æï‡Ææ‡Æ§‡Æ≤‡Æ∞‡Øç‡Æï‡Æ≥‡Øç ‡Æí‡Æ©‡Øç‡Æ±‡ØÅ ‡Æï‡ØÇ‡Æü‡ØÅ‡ÆÆ‡Øç ‡Æá‡Æü‡ÆÆ‡Øçüò±couple hills in ...   JUST GALATTA\n",
       "...                                                 ...            ...\n",
       "1039  ‡Æí‡Æ∞‡Øá ‡Æü‡Øà‡ÆÆ‡Øç‡Æ≤ ‡Æá‡Æ§‡Øç‡Æ§‡Æ©‡Øà SHOW ‡Æ§‡Æ≥‡Æ™‡Æ§‡Æø ‡ÆÆ‡Ææ‡Æ∏‡Øç ‡Æ™‡Æ£‡Øç‡Æ£‡Æø‡Æü‡Øç‡Æü‡Ææ‡Æ∞‡ØÅ ‡Æö...   JUST GALATTA\n",
       "1040  üî• ‡Æí‡Æ∞‡ØÅ ‡Æµ‡Æ¥‡Æø‡ÆØ‡Ææ ‡Æï‡Æ©‡Æµ‡ØÅ ‡Æ®‡Æø‡Æ©‡Øà‡Æµ‡Ææ‡Æ©‡Æ§‡ØÅüéâ #shortsvideo #just...   JUST GALATTA\n",
       "1041  ‡Æ™‡ØÅ‡Æ§‡ØÅ‡Æö‡Ææ ‡Æê ‡Æ™‡Øã‡Æ©‡Øç ‡Æµ‡Ææ‡Æô‡Øç‡Æï‡ØÅ‡Æ©‡Ææ ‡Æá‡Æ™‡Øç‡Æ™‡Æü‡Æø‡Æ§‡Øç‡Æ§‡Ææ‡Æ©‡Øç ‡Æ™‡Øã‡Æ≤ üî• ‡Æ§‡Æ∞‡ÆÆ‡Ææ...   JUST GALATTA\n",
       "1042  JUSTGALATTA FACK ID SCAMMER üôè ‡Æ§‡ÆØ‡Æµ‡ØÅ ‡Æö‡ØÜ‡Æû‡Øç‡Æö‡ØÅ ‡ÆØ‡Ææ‡Æ∞‡ØÅ...   JUST GALATTA\n",
       "1043  ZAM ZAM BRIYANIüî• ‡Æ™‡Æø‡Æ∞‡Æø‡ÆØ‡Ææ‡Æ£‡Æø‡Æ≤ ‡Æá‡Æ™‡Øç‡Æ™‡Æü‡Æø ‡Æï‡ØÇ‡Æü ‡Æá‡Æ∞‡ØÅ‡Æï‡Øç‡Æï‡ØÅ‡ÆÆ...   JUST GALATTA\n",
       "\n",
       "[1044 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
